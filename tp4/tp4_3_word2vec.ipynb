{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation des corpus en phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation en phrases\n",
    "\n",
    "infile = \"../tp4/data/full_left.txt\"\n",
    "outfile = \"../tp4/data/sent_left.txt\"\n",
    "\n",
    "LIMIT = None\n",
    "\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as output:\n",
    "    with open(infile, encoding=\"utf-8\", errors=\"backslashreplace\") as f:\n",
    "        content = f.readlines()\n",
    "        content = content[:LIMIT] if LIMIT is not None else content\n",
    "        n_lines = len(content)\n",
    "        for i, line in enumerate(content):\n",
    "            if i % 100 == 0:\n",
    "                print(f'processing line {i}/{n_lines}')\n",
    "            sentences = sent_tokenize(line)\n",
    "            for sent in sentences:\n",
    "                output.write(sent + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "infile = \"../tp4/data/full_right.txt\"\n",
    "outfile = \"../tp4/data/sent_right.txt\"\n",
    "\n",
    "LIMIT = None\n",
    "\n",
    "with open(outfile, 'w', encoding=\"utf-8\") as output:\n",
    "    with open(infile, encoding=\"utf-8\", errors=\"backslashreplace\") as f:\n",
    "        content = f.readlines()\n",
    "        content = content[:LIMIT] if LIMIT is not None else content\n",
    "        n_lines = len(content)\n",
    "        for i, line in enumerate(content):\n",
    "            if i % 100 == 0:\n",
    "                print(f'processing line {i}/{n_lines}')\n",
    "            sentences = sent_tokenize(line)\n",
    "            for sent in sentences:\n",
    "                output.write(sent + \"\\n\")\n",
    "print(\"Done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concaténation des expressions liées au suffrage féminin (pour pouvoir effectuer les tâches de similarité et de champ sémantique, où on ne peut manipuler que des mots uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers les fichiers\n",
    "source_file_path = \"../tp4/data/sent_left.txt\"\n",
    "destination_file_path = \"../tp4/data/sent_left_concat.txt\"\n",
    "\n",
    "# Lecture du fichier source et remplacement du texte\n",
    "with open(source_file_path, 'r', encoding='utf-8') as source_file:\n",
    "    content = source_file.read()\n",
    "    replaced_content = content.replace(\"vote des femmes\", \"votedesfemmes\") \\\n",
    "                                .replace(\"suffrage des femmes\", \"suffragedesfemmes\") \\\n",
    "                                .replace(\"suffrage féminin\", \"suffragefeminin\") \\\n",
    "                                .replace(\"vote féminin\", \"votefeminin\") \\\n",
    "                                .replace(\"suffrage feminin\", \"suffragefeminin\") \\\n",
    "                                .replace(\"vote feminin\", \"votefeminin\")\n",
    "\n",
    "# Écriture du contenu modifié dans le fichier de destination\n",
    "with open(destination_file_path, 'w', encoding='utf-8') as destination_file:\n",
    "    destination_file.write(replaced_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Chemin vers les fichiers\n",
    "source_file_path = \"../tp4/data/sent_right.txt\"\n",
    "destination_file_path = \"../tp4/data/sent_right_concat.txt\"\n",
    "\n",
    "# Lecture du fichier source et remplacement du texte\n",
    "with open(source_file_path, 'r', encoding='utf-8') as source_file:\n",
    "    content = source_file.read()\n",
    "    replaced_content = content.replace(\"vote des femmes\", \"votedesfemmes\") \\\n",
    "                                .replace(\"suffrage des femmes\", \"suffragedesfemmes\") \\\n",
    "                                .replace(\"suffrage féminin\", \"suffragefeminin\") \\\n",
    "                                .replace(\"vote féminin\", \"votefeminin\") \\\n",
    "                                .replace(\"suffrage feminin\", \"suffragefeminin\") \\\n",
    "                                .replace(\"vote feminin\", \"votefeminin\")\n",
    "\n",
    "# Écriture du contenu modifié dans le fichier de destination\n",
    "with open(destination_file_path, 'w', encoding='utf-8') as destination_file:\n",
    "    destination_file.write(replaced_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînment des modèles de langue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    \"\"\"Tokenize and Lemmatize sentences\"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename, encoding='utf-8', errors=\"backslashreplace\"):\n",
    "            yield [unidecode(w.lower()) for w in wordpunct_tokenize(line)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Droit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = f\"../tp4/data/sent_right_concat.txt\"\n",
    "sentences = MySentences(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = Phrases(sentences)\n",
    "bigram_phraser = Phraser(phrases_model=bigram_phrases)\n",
    "\n",
    "trigram_phrases = Phrases(bigram_phraser[sentences])\n",
    "trigram_phraser = Phraser(phrases_model=trigram_phrases)\n",
    "\n",
    "corpus1 = list(trigram_phraser[bigram_phraser[sentences]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus1, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=10, # La taille du \"contexte\", ici 10 mots avant et après le mot observé\n",
    "    min_count=3, # On ignore les mots qui n'apparaissent pas au moins 3 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=7 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../tp4/data/right.model\"\n",
    "model.save(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle Gauche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = f\"../tp4/data/sent_left_concat.txt\"\n",
    "sentences = MySentences(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = Phrases(sentences)\n",
    "bigram_phraser = Phraser(phrases_model=bigram_phrases)\n",
    "\n",
    "trigram_phrases = Phrases(bigram_phraser[sentences])\n",
    "trigram_phraser = Phraser(phrases_model=trigram_phrases)\n",
    "\n",
    "corpus2 = list(trigram_phraser[bigram_phraser[sentences]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus2, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=10, # La taille du \"contexte\", ici 10 mots avant et après le mot observé\n",
    "    min_count=3, # On ignore les mots qui n'apparaissent pas au moins 3 fois dans le corpus\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=7 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../tp4/data/left.model\"\n",
    "model.save(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test des modèles de langue sur les données des corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test similarité : Modèle droit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../tp4/data/right.model\")\n",
    "\n",
    "pairs = [\n",
    "    (\"suffragefeminin\", \"defavorable\"),\n",
    "    (\"suffragedesfemmes\", \"defavorable\"),\n",
    "    (\"votefeminin\", \"defavorable\"),\n",
    "    (\"votedesfemmes\", \"defavorable\"),\n",
    "    (\"suffragefeminin\", \"danger\"),     \n",
    "    (\"suffragedesfemmes\", \"danger\"),\n",
    "    (\"votefeminin\", \"danger\"),\n",
    "    (\"votedesfemmes\", \"danger\"),\n",
    "    (\"suffragefeminin\", \"risque\"),\n",
    "    (\"suffragedesfemmes\", \"risque\"),\n",
    "    (\"votefeminin\", \"risque\"),\n",
    "    (\"votedesfemmes\", \"risque\"),\n",
    "    (\"suffragefeminin\", \"menace\"),\n",
    "    (\"suffragedesfemmes\", \"menace\"),\n",
    "    (\"votefeminin\", \"menace\"),\n",
    "    (\"votedesfemmes\", \"menace\"),\n",
    "    (\"suffragefeminin\", \"mauvais\"),\n",
    "    (\"suffragedesfemmes\", \"mauvais\"),\n",
    "    (\"votefeminin\", \"mauvais\"),\n",
    "    (\"votedesfemmes\", \"mauvais\"),\n",
    "    (\"suffragefeminin\", \"avancee\"),\n",
    "    (\"suffragedesfemmes\", \"avancee\"),\n",
    "    (\"votefeminin\", \"avancee\"),\n",
    "    (\"votedesfemmes\", \"avancee\"),\n",
    "    (\"suffragefeminin\", \"progres\"),     \n",
    "    (\"suffragedesfemmes\", \"progres\"),\n",
    "    (\"votefeminin\", \"progres\"),\n",
    "    (\"votedesfemmes\", \"progres\"),\n",
    "    (\"suffragefeminin\", \"revolution\"),\n",
    "    (\"suffragedesfemmes\", \"revolution\"),\n",
    "    (\"votefeminin\", \"revolution\"),\n",
    "    (\"votedesfemmes\", \"revolution\"),\n",
    "    (\"suffragefeminin\", \"juste\"),\n",
    "    (\"suffragedesfemmes\", \"juste\"),\n",
    "    (\"votefeminin\", \"juste\"),\n",
    "    (\"votedesfemmes\", \"juste\"),\n",
    "    (\"suffragefeminin\", \"equitable\"),\n",
    "    (\"suffragedesfemmes\", \"equitable\"),\n",
    "    (\"votefeminin\", \"equitable\"),\n",
    "    (\"votedesfemmes\", \"equitable\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for pair in pairs:\n",
    "    similarity_score = model.wv.similarity(pair[0], pair[1])\n",
    "    results.append([pair[0], pair[1], similarity_score])\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"mot1\\tmot2\\tSimilarité\")\n",
    "for result in results:\n",
    "    print(f\"{result[0]}\\t{result[1]}\\t{result[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test similarité : Modèle gauche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../tp4/data/left.model\")\n",
    "\n",
    "pairs = [\n",
    "    (\"suffragefeminin\", \"defavorable\"),\n",
    "    (\"suffragedesfemmes\", \"defavorable\"),\n",
    "    (\"votefeminin\", \"defavorable\"),\n",
    "    (\"votedesfemmes\", \"defavorable\"),\n",
    "    (\"suffragefeminin\", \"danger\"),     \n",
    "    (\"suffragedesfemmes\", \"danger\"),\n",
    "    (\"votefeminin\", \"danger\"),\n",
    "    (\"votedesfemmes\", \"danger\"),\n",
    "    (\"suffragefeminin\", \"risque\"),\n",
    "    (\"suffragedesfemmes\", \"risque\"),\n",
    "    (\"votefeminin\", \"risque\"),\n",
    "    (\"votedesfemmes\", \"risque\"),\n",
    "    (\"suffragefeminin\", \"menace\"),\n",
    "    (\"suffragedesfemmes\", \"menace\"),\n",
    "    (\"votefeminin\", \"menace\"),\n",
    "    (\"votedesfemmes\", \"menace\"),\n",
    "    (\"suffragefeminin\", \"mauvais\"),\n",
    "    (\"suffragedesfemmes\", \"mauvais\"),\n",
    "    (\"suffragefeminin\", \"avancee\"),\n",
    "    (\"suffragedesfemmes\", \"avancee\"),\n",
    "    (\"votefeminin\", \"avancee\"),\n",
    "    (\"votedesfemmes\", \"avancee\"),\n",
    "    (\"suffragefeminin\", \"progres\"),     \n",
    "    (\"suffragedesfemmes\", \"progres\"),\n",
    "    (\"votefeminin\", \"progres\"),\n",
    "    (\"votedesfemmes\", \"progres\"),\n",
    "    (\"suffragefeminin\", \"revolution\"),\n",
    "    (\"suffragedesfemmes\", \"revolution\"),\n",
    "    (\"votefeminin\", \"revolution\"),\n",
    "    (\"votedesfemmes\", \"revolution\"),\n",
    "    (\"suffragefeminin\", \"juste\"),\n",
    "    (\"suffragedesfemmes\", \"juste\"),\n",
    "    (\"votefeminin\", \"juste\"),\n",
    "    (\"votedesfemmes\", \"juste\"),\n",
    "    (\"suffragefeminin\", \"equitable\"),\n",
    "    (\"suffragedesfemmes\", \"equitable\"),\n",
    "    (\"votefeminin\", \"equitable\"),\n",
    "    (\"votedesfemmes\", \"equitable\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "for pair in pairs:\n",
    "    similarity_score = model.wv.similarity(pair[0], pair[1])\n",
    "    results.append([pair[0], pair[1], similarity_score])\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"mot1\\tmot2\\tSimilarité\")\n",
    "for result in results:\n",
    "    print(f\"{result[0]}\\t{result[1]}\\t{result[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test champ lexical : Modèle droit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../tp4/data/right.model\")\n",
    "\n",
    "# Liste des mots à analyser\n",
    "mots = [\"votedesfemmes\"]\n",
    "\n",
    "# Appliquer la fonction most_similar pour chaque mot et imprimer les résultats\n",
    "for mot in mots:\n",
    "    resultats = model.wv.most_similar(mot, topn=30)\n",
    "    print(f\"Résultats pour '{mot}':\")\n",
    "    print(resultats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test champ lexical : Modèle gauche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../tp4/data/left.model\")\n",
    "\n",
    "# Liste des mots à analyser\n",
    "mots = [\"votedesfemmes\"]\n",
    "\n",
    "# Appliquer la fonction most_similar pour chaque mot et imprimer les résultats\n",
    "for mot in mots:\n",
    "    resultats = model.wv.most_similar(mot, topn=30)\n",
    "    print(f\"Résultats pour '{mot}':\")\n",
    "    print(resultats)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv_tac': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a942b0119f0c2604d4302f32a2a6e790f63eb4c9b0c297be7a26bd56fa8e02c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
